# Visual Representations â€“ Exercise 2 (Group 11)

This repository contains our solutions for **Exercise 2** of the course on Unimodal Visual Representations at TU Darmstadt.

## ğŸ“‚ Contents
- `E2.pdf` â€“ Original exercise sheet with task description  
- `E2_11.pdf` â€“ Our written group report (Group 11)  
- `E2_11.ipynb` â€“ Google Colab notebook with code and experiments  

## ğŸ‘¥ Authors
This work was completed as a **group assignment** by:  
- Mikael Alves Brito  
- Georg Matthes
- Viktor Maximilian Lehnhausen  

## ğŸ“ Description
The exercise focused on:
- Comparing **Convolutional Neural Networks (ConvNets)** and **Vision Transformers (ViTs)**  
- Understanding invariance and equivariance in both architectures  
- Implementing ResNet-style ConvNet blocks and testing variations (BasicBlockv2, BasicBlockv3)  
- Implementing a Vision Transformer (ViT) with multi-head self-attention using only `nn.Linear`  
- Training and evaluating both ConvNet and ViT models on image classification tasks  
- Experimenting with order of operations and hyperparameter modifications to improve performance  

## âš ï¸ Note
This project was created as part of a **university exercise sheet** and is **not individual work**.  
All results were prepared collaboratively by Group 11.  
